<!DOCTYPE html>
<html lang="en-us" dir="ltr">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content='有关介绍 OpenCV是一个基于Apache2.0许可（开源）发行的跨平台计算机视觉和机器学习软件库，可以运行在Linux、Windows、Android和Mac OS操作系统上。 它轻量级而且高效——由一系列 C 函数和少量 C&#43;&#43; 类构成，同时提供了Python、Ruby、MATLAB等语言的接口，实现了图像处理和计算机视觉方面的很多通用算法。它同样支持很多的AI功能，我们这里主要用Opencv来进行图像的处理，识别工作则由Mediapipe完成，有关Opencv的函数都在之前的博客上做过说明了。
Mediapipe是谷歌的一个开源的框架，它支持许多种常见的AI功能，比如人脸检测，手势跟踪，人体姿态检测等等，这次我们需要使用到的是Mediapipe的手势模型，它是谷歌官方训练并开源的一个用于手势检测的工具，因此我们就不需要自己训练模型，只需要调用这个工具就可以了。
检测原理 Mediapipe的hands检测模块通过训练好的模型，能够检测出人手上的21个关节节点，并返回它们在图像中的位置（三维），将它们在图像中标注并用线条连起来，就能够得到如下完整的手势，通过计算各点间的距离和深度就可以实现简单的手势判别。
关于环境配置 这里我使用的是pycharm,也可以使用其他开发环境，然后在下载安装mediapipe的时候发现自己用3.9版本安装不了，后来改用了3.7就没问题了（也有可能是其他原因导致的）
程序思路 导入相关的函数包后，捕获笔记本内置的摄像头（当然通过修改参数也可以改为usb连接的摄像头，比如改成1），然后对函数名进行简化（不然太长了），接着调用hands模块配置识别的参数（包括识别严谨程度，追踪信任程度等等，下面有介绍），然后简化一下用来画点和线的函数，接着可以开始设置点和线的颜色及粗细，然后再将两个变量赋值为0（后面要用来计算每秒帧数），接着写一个简单的读取视频的循环（前面的博客中有这个循环，这里不做过多介绍），然后在循环中需要将BGR图像转化为RGB图像，因为mediapipe默认读入的是RGB，而Opencv是BGR，然后将转化过的图像导入模块中进行识别，接着需要得到视频中每一帧图像的高和宽，调用.shape函数即可，然后判断如果进行模块识别之后识别到了手，那么就循环所得到的坐标，调用draw_landmarks函数画出线和点，然后使用enimerate函数列出数据及其下标（这样才能标注出该关节是第几个点），接着需要用得到的坐标乘以前面用.shape得出来的函数求出真正的x,y坐标并转化为整数（这是因为media的landmark返回的是x,y在图像中的百分比坐标，我们需要乘上宽和高才能得出数值坐标），之后我们就可以应用得到的关节坐标，调用函数在关节旁边画出对应的编号，以及打印出实时的关节坐标，接下来我们用time模块写一个小算法就可以得出每秒帧数并将其写在图像上，最后判断一下，如果按下q键，就终止循环，关闭摄像头）。
源码 import cv2 import mediapipe as mp import time#用于得知当前时间 cap = cv2.VideoCapture(0,cv2.CAP_DSHOW)#捕获摄像头,0一般是笔记本的内置摄像头，1，2，3等等则是接在usb口上的摄像头 mpHands = mp.solutions.hands#简化函数名 hands = mpHands.Hands(False,4,1,0.7,0.7)#配置侦测过程中的相关参数 mpDraw = mp.solutions.drawing_utils#画点用的函数 handLmStyle = mpDraw.DrawingSpec(color = (0,0,255),thickness = 5)#点的样式，#线的样式BGR，前一个参数是颜色，后一个是粗细 handConStyle = mpDraw.DrawingSpec(color = (0,255,0),thickness = 10)#线的样式BGR，#线的样式BGR，前一个参数是颜色，后一个是粗细 pTime = 0 cTime = 0 while True:#读取视频的循环 ret,img = cap.read()#读入每一帧图像 if ret:#如果读取不为空值，则显示画面 imgRGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)#将BGR图像转化为RGB图像，因为mediapie需要的是RGB result = hands.process(imgRGB)#导入图像进行识别 #print(result.multi_hand_landmarks) imgHeight = img.'><title>Opencv&#43;Mediapipe手势识别</title>

<link rel='canonical' href='https://SZTU-ZBK.github.io/post/blog02/'>

<link rel="stylesheet" href="/scss/style.min.5a8e892f6fa14515e9065eee1f5d2e05302606ec7f11750b2fb95198f9cdcbfd.css"><meta property='og:title' content='Opencv&#43;Mediapipe手势识别'>
<meta property='og:description' content='有关介绍 OpenCV是一个基于Apache2.0许可（开源）发行的跨平台计算机视觉和机器学习软件库，可以运行在Linux、Windows、Android和Mac OS操作系统上。 它轻量级而且高效——由一系列 C 函数和少量 C&#43;&#43; 类构成，同时提供了Python、Ruby、MATLAB等语言的接口，实现了图像处理和计算机视觉方面的很多通用算法。它同样支持很多的AI功能，我们这里主要用Opencv来进行图像的处理，识别工作则由Mediapipe完成，有关Opencv的函数都在之前的博客上做过说明了。
Mediapipe是谷歌的一个开源的框架，它支持许多种常见的AI功能，比如人脸检测，手势跟踪，人体姿态检测等等，这次我们需要使用到的是Mediapipe的手势模型，它是谷歌官方训练并开源的一个用于手势检测的工具，因此我们就不需要自己训练模型，只需要调用这个工具就可以了。
检测原理 Mediapipe的hands检测模块通过训练好的模型，能够检测出人手上的21个关节节点，并返回它们在图像中的位置（三维），将它们在图像中标注并用线条连起来，就能够得到如下完整的手势，通过计算各点间的距离和深度就可以实现简单的手势判别。
关于环境配置 这里我使用的是pycharm,也可以使用其他开发环境，然后在下载安装mediapipe的时候发现自己用3.9版本安装不了，后来改用了3.7就没问题了（也有可能是其他原因导致的）
程序思路 导入相关的函数包后，捕获笔记本内置的摄像头（当然通过修改参数也可以改为usb连接的摄像头，比如改成1），然后对函数名进行简化（不然太长了），接着调用hands模块配置识别的参数（包括识别严谨程度，追踪信任程度等等，下面有介绍），然后简化一下用来画点和线的函数，接着可以开始设置点和线的颜色及粗细，然后再将两个变量赋值为0（后面要用来计算每秒帧数），接着写一个简单的读取视频的循环（前面的博客中有这个循环，这里不做过多介绍），然后在循环中需要将BGR图像转化为RGB图像，因为mediapipe默认读入的是RGB，而Opencv是BGR，然后将转化过的图像导入模块中进行识别，接着需要得到视频中每一帧图像的高和宽，调用.shape函数即可，然后判断如果进行模块识别之后识别到了手，那么就循环所得到的坐标，调用draw_landmarks函数画出线和点，然后使用enimerate函数列出数据及其下标（这样才能标注出该关节是第几个点），接着需要用得到的坐标乘以前面用.shape得出来的函数求出真正的x,y坐标并转化为整数（这是因为media的landmark返回的是x,y在图像中的百分比坐标，我们需要乘上宽和高才能得出数值坐标），之后我们就可以应用得到的关节坐标，调用函数在关节旁边画出对应的编号，以及打印出实时的关节坐标，接下来我们用time模块写一个小算法就可以得出每秒帧数并将其写在图像上，最后判断一下，如果按下q键，就终止循环，关闭摄像头）。
源码 import cv2 import mediapipe as mp import time#用于得知当前时间 cap = cv2.VideoCapture(0,cv2.CAP_DSHOW)#捕获摄像头,0一般是笔记本的内置摄像头，1，2，3等等则是接在usb口上的摄像头 mpHands = mp.solutions.hands#简化函数名 hands = mpHands.Hands(False,4,1,0.7,0.7)#配置侦测过程中的相关参数 mpDraw = mp.solutions.drawing_utils#画点用的函数 handLmStyle = mpDraw.DrawingSpec(color = (0,0,255),thickness = 5)#点的样式，#线的样式BGR，前一个参数是颜色，后一个是粗细 handConStyle = mpDraw.DrawingSpec(color = (0,255,0),thickness = 10)#线的样式BGR，#线的样式BGR，前一个参数是颜色，后一个是粗细 pTime = 0 cTime = 0 while True:#读取视频的循环 ret,img = cap.read()#读入每一帧图像 if ret:#如果读取不为空值，则显示画面 imgRGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)#将BGR图像转化为RGB图像，因为mediapie需要的是RGB result = hands.process(imgRGB)#导入图像进行识别 #print(result.multi_hand_landmarks) imgHeight = img.'>
<meta property='og:url' content='https://SZTU-ZBK.github.io/post/blog02/'>
<meta property='og:site_name' content='My New Hugo Site'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:published_time' content='2022-07-29T12:50:22&#43;08:00'/><meta property='article:modified_time' content='2022-07-29T12:50:22&#43;08:00'/><meta property='og:image' content='https://SZTU-ZBK.github.io/img/sun.jpeg' />
<meta name="twitter:title" content="Opencv&#43;Mediapipe手势识别">
<meta name="twitter:description" content="有关介绍 OpenCV是一个基于Apache2.0许可（开源）发行的跨平台计算机视觉和机器学习软件库，可以运行在Linux、Windows、Android和Mac OS操作系统上。 它轻量级而且高效——由一系列 C 函数和少量 C&#43;&#43; 类构成，同时提供了Python、Ruby、MATLAB等语言的接口，实现了图像处理和计算机视觉方面的很多通用算法。它同样支持很多的AI功能，我们这里主要用Opencv来进行图像的处理，识别工作则由Mediapipe完成，有关Opencv的函数都在之前的博客上做过说明了。
Mediapipe是谷歌的一个开源的框架，它支持许多种常见的AI功能，比如人脸检测，手势跟踪，人体姿态检测等等，这次我们需要使用到的是Mediapipe的手势模型，它是谷歌官方训练并开源的一个用于手势检测的工具，因此我们就不需要自己训练模型，只需要调用这个工具就可以了。
检测原理 Mediapipe的hands检测模块通过训练好的模型，能够检测出人手上的21个关节节点，并返回它们在图像中的位置（三维），将它们在图像中标注并用线条连起来，就能够得到如下完整的手势，通过计算各点间的距离和深度就可以实现简单的手势判别。
关于环境配置 这里我使用的是pycharm,也可以使用其他开发环境，然后在下载安装mediapipe的时候发现自己用3.9版本安装不了，后来改用了3.7就没问题了（也有可能是其他原因导致的）
程序思路 导入相关的函数包后，捕获笔记本内置的摄像头（当然通过修改参数也可以改为usb连接的摄像头，比如改成1），然后对函数名进行简化（不然太长了），接着调用hands模块配置识别的参数（包括识别严谨程度，追踪信任程度等等，下面有介绍），然后简化一下用来画点和线的函数，接着可以开始设置点和线的颜色及粗细，然后再将两个变量赋值为0（后面要用来计算每秒帧数），接着写一个简单的读取视频的循环（前面的博客中有这个循环，这里不做过多介绍），然后在循环中需要将BGR图像转化为RGB图像，因为mediapipe默认读入的是RGB，而Opencv是BGR，然后将转化过的图像导入模块中进行识别，接着需要得到视频中每一帧图像的高和宽，调用.shape函数即可，然后判断如果进行模块识别之后识别到了手，那么就循环所得到的坐标，调用draw_landmarks函数画出线和点，然后使用enimerate函数列出数据及其下标（这样才能标注出该关节是第几个点），接着需要用得到的坐标乘以前面用.shape得出来的函数求出真正的x,y坐标并转化为整数（这是因为media的landmark返回的是x,y在图像中的百分比坐标，我们需要乘上宽和高才能得出数值坐标），之后我们就可以应用得到的关节坐标，调用函数在关节旁边画出对应的编号，以及打印出实时的关节坐标，接下来我们用time模块写一个小算法就可以得出每秒帧数并将其写在图像上，最后判断一下，如果按下q键，就终止循环，关闭摄像头）。
源码 import cv2 import mediapipe as mp import time#用于得知当前时间 cap = cv2.VideoCapture(0,cv2.CAP_DSHOW)#捕获摄像头,0一般是笔记本的内置摄像头，1，2，3等等则是接在usb口上的摄像头 mpHands = mp.solutions.hands#简化函数名 hands = mpHands.Hands(False,4,1,0.7,0.7)#配置侦测过程中的相关参数 mpDraw = mp.solutions.drawing_utils#画点用的函数 handLmStyle = mpDraw.DrawingSpec(color = (0,0,255),thickness = 5)#点的样式，#线的样式BGR，前一个参数是颜色，后一个是粗细 handConStyle = mpDraw.DrawingSpec(color = (0,255,0),thickness = 10)#线的样式BGR，#线的样式BGR，前一个参数是颜色，后一个是粗细 pTime = 0 cTime = 0 while True:#读取视频的循环 ret,img = cap.read()#读入每一帧图像 if ret:#如果读取不为空值，则显示画面 imgRGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)#将BGR图像转化为RGB图像，因为mediapie需要的是RGB result = hands.process(imgRGB)#导入图像进行识别 #print(result.multi_hand_landmarks) imgHeight = img."><meta name="twitter:card" content="img/sun.jpeg">
    <meta name="twitter:image" content='https://SZTU-ZBK.github.io/img/sun.jpeg' />
    </head>
    <body class="
    article-page
    ">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "auto");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky ">
    <button class="hamburger hamburger--spin" type="button" id="toggle-menu" aria-label="Toggle Menu">
        <span class="hamburger-box">
            <span class="hamburger-inner"></span>
        </span>
    </button>

    <header>
        
            
            <figure class="site-avatar">
                <a href="/">
                
                    
                    
                    
                        
                        <img src="/img/ava_huee0e436822bd02c2753f049c175e1b49_143024_300x0_resize_q75_box.jpg" width="300"
                            height="300" class="site-logo" loading="lazy" alt="Avatar">
                    
                
                </a>
                
                    <span class="emoji">🍥</span>
                
            </figure>
            
        
        
        <div class="site-meta">
            <h1 class="site-name"><a href="/">My New Hugo Site</a></h1>
            <h2 class="site-description">欢迎来到我的博客空间~</h2>
        </div>
    </header><ol class="social-menu">
            
                <li>
                    <a 
                        href='https://github.com/CaiJimmy/hugo-theme-stack'
                        target="_blank"
                        title="GitHub"
                    >
                        
                        
                            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M9 19c-4.3 1.4 -4.3 -2.5 -6 -3m12 5v-3.5c0 -1 .1 -1.4 -.5 -2c2.8 -.3 5.5 -1.4 5.5 -6a4.6 4.6 0 0 0 -1.3 -3.2a4.2 4.2 0 0 0 -.1 -3.2s-1.1 -.3 -3.5 1.3a12.3 12.3 0 0 0 -6.2 0c-2.4 -1.6 -3.5 -1.3 -3.5 -1.3a4.2 4.2 0 0 0 -.1 3.2a4.6 4.6 0 0 0 -1.3 3.2c0 4.6 2.7 5.7 5.5 6c-.6 .6 -.6 1.2 -.5 2v3.5" />
</svg>



                        
                    </a>
                </li>
            
                <li>
                    <a 
                        href='https://twitter.com'
                        target="_blank"
                        title="Twitter"
                    >
                        
                        
                            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-twitter" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M22 4.01c-1 .49 -1.98 .689 -3 .99c-1.121 -1.265 -2.783 -1.335 -4.38 -.737s-2.643 2.06 -2.62 3.737v1c-3.245 .083 -6.135 -1.395 -8 -4c0 0 -4.182 7.433 4 11c-1.872 1.247 -3.739 2.088 -6 2c3.308 1.803 6.913 2.423 10.034 1.517c3.58 -1.04 6.522 -3.723 7.651 -7.742a13.84 13.84 0 0 0 .497 -3.753c-.002 -.249 1.51 -2.772 1.818 -4.013z" />
</svg>



                        
                    </a>
                </li>
            
        </ol><ol class="menu" id="main-menu">
        
        

        <div class="menu-bottom-section">
            
            
                <li id="dark-mode-toggle">
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="8" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="16" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                    <span>Dark Mode</span>
                </li>
            
        </div>
    </ol>
</aside>
<main class="main full-width">
    <article class="main-article">
    <header class="article-header">

    <div class="article-details">
    

    <div class="article-title-wrapper">
        <h2 class="article-title">
            <a href="/post/blog02/">Opencv&#43;Mediapipe手势识别</a>
        </h2>
    
        
    </div>

    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">Jul 29, 2022</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    1 minute read
                </time>
            </div>
        
    </footer>
    

    
</div>
</header>

    <section class="article-content">
    
    
    <h2 id="有关介绍">有关介绍</h2>
<p>OpenCV是一个基于Apache2.0许可（开源）发行的跨平台计算机视觉和机器学习软件库，可以运行在Linux、Windows、Android和Mac OS操作系统上。 它轻量级而且高效——由一系列 C 函数和少量 C++ 类构成，同时提供了Python、Ruby、MATLAB等语言的接口，实现了图像处理和计算机视觉方面的很多通用算法。它同样支持很多的AI功能，我们这里主要用Opencv来进行图像的处理，识别工作则由Mediapipe完成，有关Opencv的函数都在之前的博客上做过说明了。</p>
<p>Mediapipe是谷歌的一个开源的框架，它支持许多种常见的AI功能，比如人脸检测，手势跟踪，人体姿态检测等等，这次我们需要使用到的是Mediapipe的手势模型，它是谷歌官方训练并开源的一个用于手势检测的工具，因此我们就不需要自己训练模型，只需要调用这个工具就可以了。</p>
<h2 id="检测原理">检测原理</h2>
<p>Mediapipe的hands检测模块通过训练好的模型，能够检测出人手上的21个关节节点，并返回它们在图像中的位置（三维），将它们在图像中标注并用线条连起来，就能够得到如下完整的手势，通过计算各点间的距离和深度就可以实现简单的手势判别。</p>
<h2 id="关于环境配置">关于环境配置</h2>
<p>这里我使用的是pycharm,也可以使用其他开发环境，然后在下载安装mediapipe的时候发现自己用3.9版本安装不了，后来改用了3.7就没问题了（也有可能是其他原因导致的）</p>
<h2 id="程序思路">程序思路 </h2>
<p>导入相关的函数包后，捕获笔记本内置的摄像头（当然通过修改参数也可以改为usb连接的摄像头，比如改成1），然后对函数名进行简化（不然太长了），接着调用hands模块配置识别的参数（包括识别严谨程度，追踪信任程度等等，下面有介绍），然后简化一下用来画点和线的函数，接着可以开始设置点和线的颜色及粗细，然后再将两个变量赋值为0（后面要用来计算每秒帧数），接着写一个简单的读取视频的循环（前面的博客中有这个循环，这里不做过多介绍），然后在循环中需要将BGR图像转化为RGB图像，因为mediapipe默认读入的是RGB，而Opencv是BGR，然后将转化过的图像导入模块中进行识别，接着需要得到视频中每一帧图像的高和宽，调用.shape函数即可，然后判断如果进行模块识别之后识别到了手，那么就循环所得到的坐标，调用draw_landmarks函数画出线和点，然后使用enimerate函数列出数据及其下标（这样才能标注出该关节是第几个点），接着需要用得到的坐标乘以前面用.shape得出来的函数求出真正的x,y坐标并转化为整数（这是因为media的landmark返回的是x,y在图像中的百分比坐标，我们需要乘上宽和高才能得出数值坐标），之后我们就可以应用得到的关节坐标，调用函数在关节旁边画出对应的编号，以及打印出实时的关节坐标，接下来我们用time模块写一个小算法就可以得出每秒帧数并将其写在图像上，最后判断一下，如果按下q键，就终止循环，关闭摄像头）。</p>
<h2 id="源码">源码</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>import cv2
</span></span><span style="display:flex;"><span>import mediapipe as mp
</span></span><span style="display:flex;"><span>import time#用于得知当前时间
</span></span><span style="display:flex;"><span>cap <span style="color:#f92672">=</span> cv2.VideoCapture<span style="color:#f92672">(</span>0,cv2.CAP_DSHOW<span style="color:#f92672">)</span><span style="color:#75715e">#捕获摄像头,0一般是笔记本的内置摄像头，1，2，3等等则是接在usb口上的摄像头</span>
</span></span><span style="display:flex;"><span>mpHands <span style="color:#f92672">=</span> mp.solutions.hands#简化函数名
</span></span><span style="display:flex;"><span>hands <span style="color:#f92672">=</span> mpHands.Hands<span style="color:#f92672">(</span>False,4,1,0.7,0.7<span style="color:#f92672">)</span><span style="color:#75715e">#配置侦测过程中的相关参数</span>
</span></span><span style="display:flex;"><span>mpDraw <span style="color:#f92672">=</span> mp.solutions.drawing_utils#画点用的函数
</span></span><span style="display:flex;"><span>handLmStyle <span style="color:#f92672">=</span> mpDraw.DrawingSpec<span style="color:#f92672">(</span>color <span style="color:#f92672">=</span> <span style="color:#f92672">(</span>0,0,255<span style="color:#f92672">)</span>,thickness <span style="color:#f92672">=</span> 5<span style="color:#f92672">)</span><span style="color:#75715e">#点的样式，#线的样式BGR，前一个参数是颜色，后一个是粗细</span>
</span></span><span style="display:flex;"><span>handConStyle <span style="color:#f92672">=</span> mpDraw.DrawingSpec<span style="color:#f92672">(</span>color <span style="color:#f92672">=</span> <span style="color:#f92672">(</span>0,255,0<span style="color:#f92672">)</span>,thickness <span style="color:#f92672">=</span> 10<span style="color:#f92672">)</span><span style="color:#75715e">#线的样式BGR，#线的样式BGR，前一个参数是颜色，后一个是粗细</span>
</span></span><span style="display:flex;"><span>pTime <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>cTime <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">while</span> True:#读取视频的循环
</span></span><span style="display:flex;"><span>    ret,img <span style="color:#f92672">=</span> cap.read<span style="color:#f92672">()</span><span style="color:#75715e">#读入每一帧图像</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> ret:#如果读取不为空值，则显示画面
</span></span><span style="display:flex;"><span>        imgRGB <span style="color:#f92672">=</span> cv2.cvtColor<span style="color:#f92672">(</span>img,cv2.COLOR_BGR2RGB<span style="color:#f92672">)</span><span style="color:#75715e">#将BGR图像转化为RGB图像，因为mediapie需要的是RGB</span>
</span></span><span style="display:flex;"><span>        result <span style="color:#f92672">=</span> hands.process<span style="color:#f92672">(</span>imgRGB<span style="color:#f92672">)</span><span style="color:#75715e">#导入图像进行识别</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">#print(result.multi_hand_landmarks)</span>
</span></span><span style="display:flex;"><span>        imgHeight <span style="color:#f92672">=</span> img.shape<span style="color:#f92672">[</span>0<span style="color:#f92672">]</span><span style="color:#75715e">#得到图像的高</span>
</span></span><span style="display:flex;"><span>        imgWeight <span style="color:#f92672">=</span> img.shape<span style="color:#f92672">[</span>1<span style="color:#f92672">]</span><span style="color:#75715e">#得到图像的宽</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> result.multi_hand_landmarks:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> handLms in result.multi_hand_landmarks:#循环一遍所有的坐标
</span></span><span style="display:flex;"><span>                mpDraw.draw_landmarks<span style="color:#f92672">(</span>img,handLms,mpHands.HAND_CONNECTIONS,handLmStyle,handConStyle<span style="color:#f92672">)</span><span style="color:#75715e">#画出点和线</span>
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">for</span> i,lm in enumerate<span style="color:#f92672">(</span>handLms.landmark<span style="color:#f92672">)</span>:
</span></span><span style="display:flex;"><span>                    xPos <span style="color:#f92672">=</span> int<span style="color:#f92672">(</span>imgWeight*lm.x<span style="color:#f92672">)</span><span style="color:#75715e">#将坐标转化为整数</span>
</span></span><span style="display:flex;"><span>                    yPos <span style="color:#f92672">=</span> int<span style="color:#f92672">(</span>imgHeight*lm.y<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>                    cv2.putText<span style="color:#f92672">(</span>img,str<span style="color:#f92672">(</span>i<span style="color:#f92672">)</span>,<span style="color:#f92672">(</span>xPos-25,yPos+5<span style="color:#f92672">)</span>,cv2.FONT_HERSHEY_PLAIN,1,<span style="color:#f92672">(</span>0,0,255<span style="color:#f92672">)</span>,2<span style="color:#f92672">)</span><span style="color:#75715e">#将手上对应的点的编号打印在图片上</span>
</span></span><span style="display:flex;"><span>                    print<span style="color:#f92672">(</span>i,xPos,yPos<span style="color:#f92672">)</span><span style="color:#75715e">#将坐标打印出来</span>
</span></span><span style="display:flex;"><span>    cTime <span style="color:#f92672">=</span> time.time<span style="color:#f92672">()</span><span style="color:#75715e">#得到当前时间</span>
</span></span><span style="display:flex;"><span>    fps <span style="color:#f92672">=</span> 1/<span style="color:#f92672">(</span>cTime-pTime<span style="color:#f92672">)</span><span style="color:#75715e">#用1除以播放一帧所用时间就可以得出每秒帧数</span>
</span></span><span style="display:flex;"><span>    pTime <span style="color:#f92672">=</span> cTime#得到这一帧结束时的时间
</span></span><span style="display:flex;"><span>    cv2.putText<span style="color:#f92672">(</span>img,f<span style="color:#e6db74">&#34;FPS:{int(fps)}&#34;</span>,<span style="color:#f92672">(</span>30,50<span style="color:#f92672">)</span>,cv2.FONT_HERSHEY_PLAIN,2,<span style="color:#f92672">(</span>255,0,0<span style="color:#f92672">)</span>,2<span style="color:#f92672">)</span><span style="color:#75715e">#将得到的帧数信息打印在图片上</span>
</span></span><span style="display:flex;"><span>    cv2.imshow<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;img&#34;</span>, img<span style="color:#f92672">)</span><span style="color:#75715e">#展示图片</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> cv2.waitKey<span style="color:#f92672">(</span>1<span style="color:#f92672">)</span> <span style="color:#f92672">==</span>ord<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;q&#34;</span><span style="color:#f92672">)</span>:#如果按下q键，则终止循环
</span></span><span style="display:flex;"><span>        break
</span></span></code></pre></div><h2 id="函数介绍不是很准确详细介绍看官网比较好">函数介绍（不是很准确，详细介绍看官网比较好）</h2>
<p>mpHands.Hands(False,4,1,0.7,0.7)：配置侦测过程中的相关参数（第六行）</p>
<p>False表示将要识别的不是一张单独的图片，是视频流，需要加上运动跟踪，如果改为True，则是读取单一图片，这里的4意思是最多识别4只手，这个可以自己看情况设置，1则是精准识别模式（会有一点消耗计算性能，但是影响不大，一般都带的动，改为可以降低计算负担，不过会降低精度）而第一个0.7意思是匹配程度需要大于70%，第二个0.7是追踪手部运动时的匹配程度也要大于70%，但是这两个参数设的越高，就需要越长的识别和判断时间，所以需要结合实际情况设置。</p>
<p>mpDraw.draw_landmarks(img,handLms,mpHands.HAND_CONNECTIONS,handLmStyle,handConStyle)：画出点和线（第二十二行）</p>
<p>img是传入的要画点和线的图像，handLms是点的坐标，mpHands.HAND_CONNECTIONS是线的类型，这里选的是是手势线条，handLmStyle是点的样式，handConStyle是线的样式。</p>
<p>cv2.putText(img,str(i),(xPos-25,yPos+5),cv2.FONT_HERSHEY_PLAIN,2,(0,0,255),2)：将手上对应的点的编号打印在图片上（二十六行）</p>
<p>img是传入的要打印内容的图像，str(i)是要打印的字符内容，cv2.FONT_HERSHEY_PLAIN是一种字体，1是字体的线条粗细，(0,0,255)是颜色设置，2是字体大小。</p>
<p>结论：mediapipe提供的识别模块还是比较方便的，同时它也提供了人体躯干，脸部检测等很多其他模块，是一个比较常用到的框架。</p>
<p>​</p>

</section>


    <footer class="article-footer">
    

    
    <section class="article-copyright">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <path d="M14.5 9a3.5 4 0 1 0 0 6" />
</svg>



        <span>Licensed under CC BY-NC-SA 4.0</span>
    </section>
    </footer>


    
</article>

    

    

     
    
        
    <div class="disqus-container">
    
</div>

<style>
    .disqus-container {
        background-color: var(--card-background);
        border-radius: var(--card-border-radius);
        box-shadow: var(--shadow-l1);
        padding: var(--card-padding);
    }
</style>

<script>
    window.addEventListener('onColorSchemeChange', (e) => {
        if (typeof DISQUS == 'object') {
            DISQUS.reset({
                reload: true
            });
        }
    })
</script>

    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
            2020 - 
        
        2022 My New Hugo Site
    </section>
    
    <section class="powerby">
        Built with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> <br />
        Theme <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="3.12.0">Stack</a></b> designed by <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a>
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css"crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css"crossorigin="anonymous"
            >

            </main>
    <aside class="sidebar right-sidebar sticky">
        
            
                
    <section class="widget archives">
        <div class="widget-icon">
            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <line x1="5" y1="9" x2="19" y2="9" />
  <line x1="5" y1="15" x2="19" y2="15" />
  <line x1="11" y1="4" x2="7" y2="20" />
  <line x1="17" y1="4" x2="13" y2="20" />
</svg>



        </div>
        <h2 class="widget-title section-title">Table of contents</h2>
        
        <div class="widget--toc">
            <nav id="TableOfContents">
  <ul>
    <li><a href="#有关介绍">有关介绍</a></li>
    <li><a href="#检测原理">检测原理</a></li>
    <li><a href="#关于环境配置">关于环境配置</a></li>
    <li><a href="#程序思路">程序思路 </a></li>
    <li><a href="#源码">源码</a></li>
    <li><a href="#函数介绍不是很准确详细介绍看官网比较好">函数介绍（不是很准确，详细介绍看官网比较好）</a></li>
  </ul>
</nav>
        </div>
    </section>

            
        
    </aside>


        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js"integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z&#43;KMkF24hUW8WePSA9HM="crossorigin="anonymous"
                
                >
            </script><script type="text/javascript" src="/ts/main.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>

    </body>
</html>
